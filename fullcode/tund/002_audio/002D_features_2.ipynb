{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load audio into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/root/code/male/tests/example_data/audio1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sampling_rate = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampling_rate)\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = len(samples) / sampling_rate\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "librosa.display.waveplot(y=samples, sr=sampling_rate)\n",
    "plt.xlabel('Time (seconds) --->')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform (FFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Sine Wave to Understand FFT\n",
    "\n",
    "To understand the output of FFT, let’s create a simple sine wave. The following piece of code creates a sine wave with a sampling rate = 100, amplitude = 1 and frequency = 3. Amplitude values are calculated every 1/100th second (sampling rate) and stored into a list called y1. We will pass these discrete amplitude values to calculate DFT of this signal using the FFT algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100\n",
    "f = 3\n",
    "x = np.arange(samples)\n",
    "y1 = np.sin(2 * np.pi * f * (x / samples))  # amplitude\n",
    "plt.figure()\n",
    "plt.stem(x, y1, 'r')\n",
    "plt.plot(x, y1)\n",
    "plt.xlabel('Time --->')\n",
    "plt.ylabel('<-- Amplitude -->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a sequence of amplitudes stored in list y1. We will pass this sequence to the FFT algorithm implemented by scipy. This algorithm returns a list yf of complex-valued amplitudes of the frequencies found in the signal. The first half of this list returns positive-frequency-terms, and the other half returns negative-frequency-terms which are similar to the positive ones. You can pick out any one half and calculate absolute values to represent the frequencies present in the signal. Following function takes samples as input and plots the frequency graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_plot(audio, sampling_rate):\n",
    "    n = len(audio)\n",
    "    T = 1 / sampling_rate\n",
    "    yf = scipy.fft.fft(audio)\n",
    "    xf = np.linspace(0.0, 1.0 / (2.0 * T), n // 2)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xf, 2.0 / n * np.abs(yf[:n // 2]))\n",
    "    plt.grid()\n",
    "    plt.xlabel('Frequency --->')\n",
    "    plt.ylabel('Magnitude')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_plot(y1, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check out the output of FFT for a signal having more than one frequency, Let’s create another sine wave. This time we will keep sampling rate = 100, amplitude = 2 and frequency value = 11. Following code generates this signal and plots the sine wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100\n",
    "f = 11\n",
    "x = np.arange(samples)\n",
    "y2 = np.sin(2 * np.pi * f * (x / samples))  # amplitude\n",
    "plt.figure()\n",
    "plt.stem(x, y2, 'r')\n",
    "plt.plot(x, y2)\n",
    "plt.xlabel('Time --->')\n",
    "plt.ylabel('<-- Amplitude -->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have kept the sampling rate = 100 because later we are going to add this signal to our old sine wave.<br>\n",
    "Obviously FFT function will show a single spike with frequency = 11 for this wave also. But we want to see what happens if we add these two signals of the same sampling rate but the different frequency and amplitude values. Here sequence y3 will represent the resultant signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = y1 + y2\n",
    "plt.figure()\n",
    "plt.stem(x, y3, 'r')\n",
    "plt.plot(x, y3)\n",
    "plt.xlabel('Time --->')\n",
    "plt.ylabel('<-- Amplitude -->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_plot(y3, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT on our Audio signal\n",
    "\n",
    "Now that we have seen how this FFT algorithm gives us all the frequencies in a given signal. let’s try to pass our original audio signal into this function. We are using the same audio clip we loaded earlier into the python with a sampling rate = 16000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sampling_rate = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_plot(samples, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(samples, sample_rate, stride_ms=10.0, window_ms=20.0, max_freq=None, eps=1e-14):\n",
    "\n",
    "    stride_size = int(0.001 * sample_rate * stride_ms)\n",
    "    window_size = int(0.001 * sample_rate * window_ms)\n",
    "\n",
    "    # Extract strided windows\n",
    "    truncate_size = (len(samples) - window_size) % stride_size\n",
    "    samples = samples[:len(samples) - truncate_size]\n",
    "    nshape = (window_size, (len(samples) - window_size) // stride_size + 1)\n",
    "    nstrides = (samples.strides[0], samples.strides[0] * stride_size)\n",
    "    windows = np.lib.stride_tricks.as_strided(samples, shape = nshape, strides = nstrides)\n",
    "    \n",
    "    assert np.all(windows[:, 1] == samples[stride_size:(stride_size + window_size)])\n",
    "\n",
    "    # Window weighting, squared Fast Fourier Transform (fft), scaling\n",
    "    weighting = np.hanning(window_size)[:, None]\n",
    "    \n",
    "    fft = np.fft.rfft(windows * weighting, axis=0)\n",
    "    fft = np.absolute(fft)\n",
    "    fft = fft ** 2\n",
    "    \n",
    "    scale = np.sum(weighting ** 2) * sample_rate\n",
    "    fft[1:-1, :] *= (2.0 / scale)\n",
    "    fft[(0, -1), :] /= scale\n",
    "    \n",
    "    # Prepare fft frequency list\n",
    "    freqs = float(sample_rate) / window_size * np.arange(fft.shape[0])\n",
    "    \n",
    "    # Compute spectrogram feature\n",
    "    ind = np.where(freqs <= max_freq)[0][-1] + 1\n",
    "    specgram = np.log(fft[:ind, :] + eps)\n",
    "    return specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram(samples, sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
